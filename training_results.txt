################################################################################
                       Learning iteration 299/300                       

                       Computation: 111597 steps/s (collection: 0.796s, learning 0.085s)
             Mean action noise std: 1.03
          Mean value_function loss: 0.1997
               Mean surrogate loss: -0.0056
                 Mean entropy loss: 17.0639
                       Mean reward: 366.58
               Mean episode length: 1000.00
Episode_Reward/track_lin_vel_xy_exp: 17.2551
Episode_Reward/track_ang_vel_z_exp: 3.7181
       Episode_Reward/lin_vel_z_l2: -0.0230
      Episode_Reward/ang_vel_xy_l2: -1.0876
     Episode_Reward/dof_torques_l2: -0.0015
         Episode_Reward/dof_acc_l2: -1.0585
     Episode_Reward/action_rate_l2: -0.1169
      Episode_Reward/feet_air_time: -0.1978
 Episode_Reward/undesired_contacts: -0.0347
Episode_Reward/flat_orientation_l2: -0.0993
     Episode_Reward/dof_pos_limits: 0.0000
Metrics/base_velocity/error_vel_xy: 0.2234
Metrics/base_velocity/error_vel_yaw: 0.9012
      Episode_Termination/time_out: 3.8333
  Episode_Termination/base_contact: 0.0000
--------------------------------------------------------------------------------
                   Total timesteps: 29491200
                    Iteration time: 0.88s
                      Time elapsed: 00:04:28
                               ETA: 00:00:00